\subsection{User Interview} \label{sec:user}

To collect feedbacks from users that are not familiar with \qevis{}, we interviewed two domain experts. One of them focuses on query optimization (\textit{EA}) while the other works on designing distributed database system (\textit{EB}). Both of them are familiar with Hive and Hadoop and need to understand the query execution progress but do not know \qevis{} before the interview. In the interview, we started by explaining our visualization design. Then we demonstrated to them how the system works in the case studies above. At last, they were invited to use \qevis{} to explore several queries at their choices. Both of them agree that \qevis{} greatly improves the effectiveness and efficiency in understanding and diagnosing query execution.       


\stitle{Methodology}
Both \textit{EA} and \textit{EB} agree that analyzing query execution at the task level is necessary to provide sufficient information for reasoning query performance, especially after they saw how resource deadlock was detected and explained in the case study. \textit{EA} comments that interactive exploration at the task level enables him to perform fine-grained analysis about system behavior and pinpoint tasks of interest from many tasks. \textit{EB} confirms the effectiveness of a visual analytics system, he comments that ``using an interactive visual system to analyze query performance is much more efficient than checking system logs". \textit{EA} also likes the design that integrates system performance with task execution as it allows easy identification of performance bottleneck. 

\stitle{Visualization and interaction design}
Both interviewees think the visualization designs enable them to make more sense of the query execution process, especially about how a large number of tasks are executed across the cluster. \textit{EB} highly praised the scatter-based task distribution visualization as it can intuitively highlight the tasks worth analyzing. He comments ``given a task distribution, I can quickly tell what happens to the data system". \textit{EA} agrees that the task distribution effectively shows the overall execution statues of the tasks. \textit{EA} also comments on the progress view, ``vertex level progress with a clear dependency is helpful for getting an overview of query execution." For \textit{EB}, it was difficult for him to understand the visual encoding of the task dependencies in the beginning. But after exploration, he thought it is a good idea as it clearly shows which tasks are delayed.
All experts think the interactions, such as hovering, filtering, sorting and linking across views, are useful for them to switch their focuses. ``The interactions make the exploration easy, as I can focus on any elements I am interested in" commented by \textit{EB}.

\stitle{Limitations and possible improvements}
\textit{EA} points out that the task dependencies may overlap with the task dots when they are both close to the diagonal line. He also recommends us to add intuitive visualizations for the query parameters and different types of operators (e.g., join, filter and projection) as they are also helpful in reasoning query performance. \textit{EB} encourages us to add more functionalities such as supporting visual comparison among the execution processes of multiple queries.